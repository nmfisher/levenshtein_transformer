{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.nn.modules.transformer import Transformer, TransformerEncoder, TransformerEncoderLayer\n",
    "from pytorch_transformers.tokenization_distilbert import DistilBertTokenizer\n",
    "from pytorch_transformers.modeling_distilbert import DistilBertModel\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch import optim\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "from torch import nn\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "special_tokens_dict = {'additional_special_tokens': ['<PLH>']}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "encoder = DistilBertModel.from_pretrained('distilbert-base-uncased').cuda()\n",
    "encoder.resize_token_embeddings(len(tokenizer))  \n",
    "\n",
    "noop = \"N\"\n",
    "sub = \"S\"\n",
    "insert = \"I\"\n",
    "delete = \"D\"\n",
    "\n",
    "def ld(s1, s2, subcost=1, delcost=1, inscost=1):\n",
    "    operations = [[\"\" for j in range(len(s2) + 1)] for i in range(len(s1) + 1)]\n",
    "    \n",
    "    matrix = np.zeros((len(s1)+1, len(s2)+1))\n",
    "    \n",
    "    for j in range(len(s2) + 1):\n",
    "        matrix[0,j] = j\n",
    "        operations[0][j] = insert\n",
    "        for i in range(len(s1) + 1):\n",
    "            matrix[i,0] = i\n",
    "            operations[i][0] = insert\n",
    "            if i > 0 and j > 0:\n",
    "                subCost = matrix[i-1, j-1] if s1[i-1] == s2[j-1] else matrix[i-1, j-1] + subcost\n",
    "                insertCost = matrix[i, j-1] + inscost\n",
    "                deleteCost = matrix[i-1, j] + delcost\n",
    "                minCost = min(subCost, insertCost, deleteCost)\n",
    "                matrix[i,j] = minCost\n",
    "                if minCost == 0:\n",
    "                    operations[i][j] = noop\n",
    "                elif minCost == deleteCost:\n",
    "                    operations[i][j] = delete\n",
    "                elif minCost == insertCost:\n",
    "                    operations[i][j] = insert\n",
    "                elif minCost == subCost:\n",
    "                    operations[i][j] = sub\n",
    "    i = len(s1)\n",
    "    j = len(s2)\n",
    "    history = []\n",
    "    while j > 0 or i > 0:        \n",
    "        if delcost != np.inf:\n",
    "            if j == 0:\n",
    "                history.append(delete)\n",
    "                i -= 1\n",
    "                continue\n",
    "            if matrix[i-1][j-1] < matrix[i-1,j]:\n",
    "                history.append(noop)\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            else:\n",
    "                history.append(delete)\n",
    "                i -= 1\n",
    "        elif inscost != np.inf:\n",
    "            if j == 0:\n",
    "                history.append(noop)\n",
    "                i -= 1\n",
    "                continue\n",
    "            if matrix[i-1][j-1] < matrix[i,j-1]:\n",
    "                history.append(noop)\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            else:\n",
    "                history.append((insert,s2[j-1]))\n",
    "                #history.append(insert)\n",
    "                j -= 1\n",
    "    history.reverse()\n",
    "    return matrix, matrix[len(s1),len(s2)], history\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path, \"r\") as infile:\n",
    "            self.data = json.load(infile)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"Data\"])\n",
    "\n",
    "    def sample(self):\n",
    "        key = \"Question\" if random.random() > 0.5 else \"Answer\"\n",
    "        return self.data[\"Data\"][random.randint(0, len(self.data[\"Data\"]))][\"Question\"]\n",
    "    \n",
    "PLH = \"<PLH>\"\n",
    "TS = \"<s>\"\n",
    "TE = \"</s>\"\n",
    "\n",
    "class PlaceholderClassifier(nn.Module):\n",
    "    def __init__(self, hsz, transformer, max_placeholders=10):\n",
    "        super().__init__()\n",
    "        self.transformer = transformer\n",
    "        self.dense = nn.Linear(\n",
    "            hsz, max_placeholders,\n",
    "        )\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        return self.dense(self.transformer(input))\n",
    "    \n",
    "class TokenClassifier(nn.Module):    \n",
    "    def __init__(self, hsz, transformer, vsz, max_seq_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformer = transformer\n",
    "        \n",
    "        self.dense = nn.Linear(\n",
    "            hsz, vsz\n",
    "        )\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        return self.dense(self.transformer(input))\n",
    "        \n",
    "class DeletionClassifier(nn.Module):    \n",
    "    def __init__(self, hsz, transformer):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformer = transformer\n",
    "\n",
    "        self.dense = nn.Linear(\n",
    "            hsz, 2,\n",
    "        )\n",
    "    def forward(self, input, hidden=None):\n",
    "        return self.dense(self.transformer(input))\n",
    "\n",
    "dataset = QADataset(\"/virtualmachines/data/trivia_qa/qa/wikipedia-train.json\")\n",
    "dataset.sample()\n",
    "plh = tokenizer.encode(\"<PLH>\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleted_indices_to_placeholders(deleted, max_placeholders):\n",
    "    i = 0\n",
    "    placeholders = []\n",
    "    num_deleted = 0\n",
    "    while True:\n",
    "        if i == len(deleted):\n",
    "            if num_deleted > 0:\n",
    "                placeholders.append(min(num_deleted, max_placeholders))\n",
    "            break\n",
    "        if deleted[i] == 1:\n",
    "            num_deleted += 1\n",
    "        else:\n",
    "            if num_deleted > 0:\n",
    "                placeholders.append(min(num_deleted, max_placeholders))\n",
    "            placeholders.append(0)\n",
    "            num_deleted = 0\n",
    "        i += 1\n",
    "    while len(placeholders) < len(deleted):\n",
    "        placeholders.append(0)\n",
    "    return torch.unsqueeze(torch.LongTensor(placeholders), 0)\n",
    "\n",
    "\n",
    "#delete_random([tokenizer.encode(\"Hello, my name is \"), tokenizer.encode(\"What is your name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_minimal(y, y_ground, pad=True, max_placeholders=0):\n",
    "    \"\"\"Apply the sequence of deletions from y that give the smallest possible Levenshtein distance from y_ground\n",
    "    Returns tensors of:\n",
    "    - the token sequence post-deletion\n",
    "    - the token sequence post-deletion, with PLH inserted at each deleted position\n",
    "    - the number of placeholders inserted at each post-deletion index\n",
    "    \"\"\"\n",
    "    batched = torch.zeros(len(y),)\n",
    "    \n",
    "    # if y_ground is longer than y, there is no sequence of deletes with a shorter distance\n",
    "    if len(y_ground) > len(y): \n",
    "        return y\n",
    "    \n",
    "    # calculate LD directly against tokens\n",
    "    deleted = []\n",
    "    matrix, dist, edits = ld(y.numpy(),y_ground.numpy(), subcost=np.inf, inscost=np.inf)\n",
    "    num_deleted = 0\n",
    "    for i in range(len(edits)):\n",
    "        if edits[i] == \"D\":\n",
    "            deleted.append(1)\n",
    "            num_deleted += 1\n",
    "        else:\n",
    "            deleted.append(0)\n",
    "    placeholders = deleted_indices_to_placeholders(deleted,max_placeholders=max_placeholders)\n",
    "    post_deletion, post_deletion_with_placeholders = deleted_boolean_to_tensors(y, deleted, num_deleted)    \n",
    "    return post_deletion, post_deletion_with_placeholders, torch.LongTensor([deleted])#,placeholders\n",
    "\n",
    "def pad(items, pad_len=0, pad_token=0):\n",
    "    if pad_len == 0:\n",
    "        pad_len = max([len(i) for i in items])\n",
    "    copy = items.copy()\n",
    "    for i in copy:\n",
    "        while len(i) < pad_len:\n",
    "            i.append(pad_token)\n",
    "    return copy\n",
    "    \n",
    "def insert_minimal(y, y_ground,max_placeholders):\n",
    "    \"\"\"Apply the sequence of insertions to y resulting in the smallest possible Levenshtein distance from y_ground\n",
    "    Accepts tensor of:\n",
    "    - bsz * max_seq_len\n",
    "    Returns tensors of:\n",
    "    - size (n+1), where the value at position 0 <= i < n represents the number of PLH tags inserted at that position\n",
    "        - n is the number of tokens in y\n",
    "    - size(k) containing the indices of each inserted token, where k is the total number of tokens added\n",
    "    - size(n+k) containing the tokens of the entire post-insertion sequence\n",
    "    \"\"\"\n",
    "\n",
    "    batch_placeholders = []\n",
    "    batch_inserted = []\n",
    "    batch_new = []\n",
    "    for batch_idx in range(len(y)):\n",
    "        matrix, dist, edits = ld(y[batch_idx],y_ground[batch_idx], subcost=np.inf, delcost=np.inf)\n",
    "        inserted = 0\n",
    "        y_placeholders = []\n",
    "        y_inserted = []\n",
    "        y_new = []\n",
    "        y_idx = 0\n",
    "        i = 0\n",
    "        while i < len(edits):\n",
    "            if edits[i][0] == \"I\":\n",
    "                accum = 0\n",
    "                while i < len(edits) and edits[i][0] == \"I\":\n",
    "                    y_inserted.append(edits[i][1])\n",
    "                    y_new.append(edits[i][1])\n",
    "                    accum += 1\n",
    "                    i += 1\n",
    "                y_placeholders.append(min(accum,max_placeholders-1))\n",
    "            else:\n",
    "                y_placeholders.append(0)\n",
    "                y_new.append(y[batch_idx][y_idx])\n",
    "                i += 1\n",
    "                y_idx += 1\n",
    "        batch_placeholders.append(y_placeholders)\n",
    "        batch_inserted.append(y_inserted)\n",
    "        batch_new.append(y_new)\n",
    "    batch_placeholders = pad(batch_placeholders, pad_token=tokenizer.pad_token_id)\n",
    "\n",
    "    batch_new = pad(batch_new, pad_token=tokenizer.pad_token_id)\n",
    "    \n",
    "    return batch_placeholders, batch_inserted, torch.LongTensor(batch_new)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 30522, 1, 2, 30522, 3, 30522, 4]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_deletion(source, deletions):\n",
    "    return [source[i].item() for i in range(len(source)) if deletions[i] == 0]\n",
    "\n",
    "def apply_placeholders(source, placeholders):\n",
    "    if type(source) == list:\n",
    "            source = torch.LongTensor(source)\n",
    "    if type(placeholders) == list:\n",
    "        placeholders = torch.LongTensor(placeholders)\n",
    "            \n",
    "    def generate():\n",
    "        for i in range(placeholders.size(0)):\n",
    "            for j in range(placeholders[i]):\n",
    "                yield plh\n",
    "            if i < len(source):\n",
    "                yield source[i].item()\n",
    "    generated = list(generate())\n",
    "    return generated\n",
    "\n",
    "apply_placeholders(torch.LongTensor([0,1,2,3,4]), torch.LongTensor([0,1,0,1,1]))\n",
    "#apply_deletion(torch.LongTensor([2210,5501,2001]), torch.LongTensor([0,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsertionInput():\n",
    "    '''\n",
    "    Wraps tensors of;\n",
    "    - the original sequence\n",
    "    - the post-deletion sequence\n",
    "    - the post-deletion sequence (including placeholders)\n",
    "    - boolean indicating whether the tokens at index i was deleted\n",
    "    '''\n",
    "    def __init__(self, ground, p_del=0.25):\n",
    "        self.ground = ground\n",
    "        self.p_del = p_del\n",
    "        self.delete_random()\n",
    "    \n",
    "    def delete_random(self):\n",
    "        \"\"\"Deletes token(s) randomly from the passed (tokenized) string with probability p\n",
    "        Accepts:\n",
    "        - a list of token sequences bsz * pad_length\n",
    "        Returns tensors of:\n",
    "        - the token sequence post-deletion\n",
    "        - the token sequence post-deletion, with PLH inserted at each deleted position\n",
    "        - the number of placeholders inserted at each post-deletion index\n",
    "        \"\"\"\n",
    "        self.deleted_indices = []\n",
    "        self.post_deletion = []\n",
    "        self.post_deletion_with_placeholders = []\n",
    "        for entry in self.ground:\n",
    "            indices = []\n",
    "            post_deletion_with_placeholders = []\n",
    "            post_deletion = []\n",
    "            for token in entry:\n",
    "                if random.random() < self.p_del:\n",
    "                    indices.append(1)\n",
    "                    post_deletion_with_placeholders.append(plh)\n",
    "                else:\n",
    "                    indices.append(0)\n",
    "                    post_deletion.append(token)\n",
    "                    post_deletion_with_placeholders.append(token)\n",
    "            self.deleted_indices.append(indices)\n",
    "            self.post_deletion_with_placeholders.append(post_deletion_with_placeholders)\n",
    "            self.post_deletion.append(post_deletion)\n",
    "        self.num_placeholders = []\n",
    "        for entry in self.post_deletion_with_placeholders:\n",
    "            num_placeholders = []\n",
    "            accum = 0\n",
    "            for token in entry:\n",
    "                if token == plh:\n",
    "                    accum += 1\n",
    "                    continue\n",
    "                if accum > 0:\n",
    "                    num_placeholders.append(accum)\n",
    "                    accum = 0\n",
    "                num_placeholders.append(accum)\n",
    "            if accum > 0:\n",
    "                num_placeholders.append(accum)\n",
    "            self.num_placeholders.append(num_placeholders)\n",
    "        self.post_deletion = pad(self.post_deletion, pad_len=100)\n",
    "        self.num_placeholders = pad(self.num_placeholders, pad_len=100)\n",
    "        self.post_deletion_with_placeholders = pad(self.post_deletion_with_placeholders, pad_len=100)\n",
    "        self.num_placeholders = torch.LongTensor(self.num_placeholders)\n",
    "        self.post_deletion = torch.LongTensor(self.post_deletion)\n",
    "        if self.num_placeholders.size() != self.post_deletion.size():\n",
    "            print(self.num_placeholders)\n",
    "            print(self.post_deletion)\n",
    "            raise Exception()\n",
    "        self.post_deletion_with_placeholders = torch.LongTensor(self.post_deletion_with_placeholders)\n",
    "\n",
    "class DeletionInput():\n",
    "    \"\"\"Randomly inserts tokens into the sequence\n",
    "    Wraps tensors of:\n",
    "    - the post-insertion sequence\n",
    "    - the indices of the inserted tokens\n",
    "    \"\"\" \n",
    "    def __init__(self, insertion_input, t_classifier, p_ins=0.25, max_inserts=5):\n",
    "        ground = insertion_input.ground.copy()\n",
    "        bsz = len(ground)\n",
    "        self.placeholder_indices = [] \n",
    "        for batch_idx in range(bsz):\n",
    "            i = 0\n",
    "            placeholder_indices = []\n",
    "            inserted = 0\n",
    "            for i in range(len(ground[batch_idx]) + 1):\n",
    "                if random.random() < p_ins and inserted < max_inserts:\n",
    "                    placeholder_indices.append(1)\n",
    "                    inserted += 1\n",
    "                if i < len(ground[batch_idx]):\n",
    "                    placeholder_indices.append(0)\n",
    "            ground[batch_idx] = list(apply_placeholders(ground[batch_idx], placeholder_indices))\n",
    "            self.inserted_indices = [1 if ground[batch_idx][i] == plh else 0 for i in range(len(ground[batch_idx]))]\n",
    "            self.inserted_indices = torch.LongTensor(pad([self.inserted_indices],pad_len=100))\n",
    "            self.placeholder_indices.append(placeholder_indices)\n",
    "        \n",
    "        self.post_insertion = torch.LongTensor(pad(ground, pad_len=100))\n",
    "        \n",
    "        insert_tokens = torch.argmax(t_classifier(encoder(self.post_insertion.cuda())[0].cuda()),dim=2)\n",
    "        \n",
    "        assert insert_tokens.size() == self.post_insertion.size()\n",
    "        \n",
    "        for batch_idx in range(bsz):\n",
    "            for i in range(insert_tokens.size(1)):\n",
    "                if self.post_insertion[batch_idx,i] == plh:\n",
    "                    self.post_insertion[batch_idx,i] = insert_tokens[batch_idx,i]\n",
    "        \n",
    "        self.placeholder_indices = pad(self.placeholder_indices,pad_len=100)\n",
    "        self.placeholder_indices = torch.LongTensor(self.placeholder_indices)\n",
    "        self.ground_padded = pad(insertion_input.ground, pad_len=100)\n",
    "#insertion_input = InsertionInput([tokenizer.encode(\"Hi my friend\")])\n",
    "#deletion_input = DeletionInput(insertion_input, TokenClassifier(100, len(tokenizer), 20))\n",
    "#tokenizer.decode(deletion_input.post_insertion[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Ground \n",
      " which surrey town officially added the suffix'- upon - thames'to its name in may 2012?                                                                                \n",
      "Input to deletion classifier \n",
      " which surrey town officially added  the suffix'- upon - thames 'to its name in may 2012 ?                                                                             \n",
      "Expected deletion classifier output \n",
      " which surrey town officially added the suffix'- upon - thames'to its name in may 2012?                                                                             \n",
      "Input to placeholder classifier \n",
      " town officially added the suffix'- upon - thames'to its name 2012                                                                                     \n",
      "Expected placeholder classifier output \n",
      "  <PLH> <PLH>town officially added the suffix'- upon - thames'to its name 2012 <PLH> <PLH>  <PLH>                                                                                  \n",
      "Input to insertion classifier \n",
      "  <PLH> <PLH>town officially added the suffix'- upon - thames'to its name <PLH> <PLH>2012 <PLH>                                                                               \n",
      "Expected insertion classifier output \n",
      " which surrey town officially added the suffix'- upon - thames'to its name in may 2012?                                                                                \n",
      "50\n",
      "Ground \n",
      " in medicine, belonephobia is an irrational fear of what?                                                                                       \n",
      "Input to deletion classifier \n",
      " in medicine, belonephobia  is an irrational fear of what ?                                                                                     \n",
      "Expected deletion classifier output \n",
      " in medicine, belonephobia is an irrational fear of what?                                                                                    \n",
      "Input to placeholder classifier \n",
      " in,one is an irrational fear of?                                                                                           \n",
      "Expected placeholder classifier output \n",
      " in <PLH>,one <PLH>is an <PLH>irrational fear of?   <PLH>                                                                                        \n",
      "Input to insertion classifier \n",
      " in <PLH>, <PLH>##one <PLH>is an irrational fear of <PLH>?                                                                                       \n",
      "Expected insertion classifier output \n",
      " in medicine, belonephobia is an irrational fear of what?                                                                                       \n",
      "50\n",
      "tensor(7.0629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " italy controlled which country from 1911 to 1943?                                                                                           \n",
      "Ground truth post-deletion \n",
      " italy controlled which country from 1911 to?                                                                                            \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " italy controlled which country from 1911 to?                                                                                            \n",
      "Post-placeholders \n",
      " italy controlled which country from 1911 to?                                                                                            \n",
      "Post-insert \n",
      " italy controlled which country from 1911 to?                                                                                            \n",
      "italy controlled which country from 1911 to? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "75\n",
      "Ground \n",
      " which is the largest desert in south america?                                                                                           \n",
      "Input to deletion classifier \n",
      " which  is the largest desert in south america?                                                                                          \n",
      "Expected deletion classifier output \n",
      " which is the largest desert in south america?                                                                                          \n",
      "Input to placeholder classifier \n",
      " is the in south america?                                                                                              \n",
      "Expected placeholder classifier output \n",
      "  <PLH>is the in <PLH> <PLH>south america?                                                                                              \n",
      "Input to insertion classifier \n",
      "  <PLH>is the <PLH> <PLH>in south america?                                                                                           \n",
      "Expected insertion classifier output \n",
      " which is the largest desert in south america?                                                                                           \n",
      "100\n",
      "Ground \n",
      " electrum is a naturally occurring alloy of gold and which other metal?                                                                                      \n",
      "Input to deletion classifier \n",
      " electrum is a naturally occurring  alloy of gold and which other metal ?                                                                                    \n",
      "Expected deletion classifier output \n",
      " electrum is a naturally occurring alloy of gold and which other metal?                                                                                    \n",
      "Input to placeholder classifier \n",
      " electrum is a occurring alloy of gold which metal                                                                                          \n",
      "Expected placeholder classifier output \n",
      " electrum is a <PLH>occurring alloy of gold which <PLH>metal  <PLH>  <PLH>                                                                                      \n",
      "Input to insertion classifier \n",
      " electrum is a <PLH>occurring alloy of gold <PLH>which <PLH>metal <PLH>                                                                                     \n",
      "Expected insertion classifier output \n",
      " electrum is a naturally occurring alloy of gold and which other metal?                                                                                      \n",
      "100\n",
      "tensor(2.8610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " hans holbein the younger was court painter to which king?                                                                                       \n",
      "Ground truth post-deletion \n",
      " hans holb the was painter to which                                                                                            \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " hans holb the was painter to which                                                                                            \n",
      "Post-placeholders \n",
      " hans holb the was painter to which                                                                                            \n",
      "Post-insert \n",
      " hans holb the was painter to which                                                                                            \n",
      "hans holb the was painter to which [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "125\n",
      "Ground \n",
      " ' janjaweed ', an arabic word that literally translates to'devil on a horse'has achieved infamy by its association with a dubious group in which current day crisis in sudan?                                                             \n",
      "Input to deletion classifier \n",
      " ' janjaweed ', an arabic word  that literally translates to'devil on  a horse'has achieved  infa my by its association with a dubious group in which  current day crisis in sudan?                                                        \n",
      "Expected deletion classifier output \n",
      " ' janjaweed ', an arabic word that literally translates to'devil on a horse'has achieved infamy by its association with a dubious group in which current day crisis in sudan?                                                        \n",
      "Input to placeholder classifier \n",
      " ' janweed ', an arabic word that literally translates to'devil on a horse'has infamy its association with a dubious group in which current day crisis sudan?                                                                 \n",
      "Expected placeholder classifier output \n",
      " ' jan <PLH>##weed ', an arabic word that literally translates to'devil on a horse'has in <PLH>##famy its association <PLH>with a dubious group in which current day crisis sudan?  <PLH>                                                               \n",
      "Input to insertion classifier \n",
      " ' jan <PLH>##weed ', an arabic word that literally translates to'devil on a horse'has <PLH>infamy <PLH>its association with a dubious group in which current day crisis <PLH>sudan?                                                             \n",
      "Expected insertion classifier output \n",
      " ' janjaweed ', an arabic word that literally translates to'devil on a horse'has achieved infamy by its association with a dubious group in which current day crisis in sudan?                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "Ground \n",
      " in monopoly, the green coloured properties are regent street, oxford street and what else?                                                                                   \n",
      "Input to deletion classifier \n",
      " in monopoly, the green  coloured properties  are regent  street, oxford  street and what else?                                                                               \n",
      "Expected deletion classifier output \n",
      " in monopoly, the green coloured properties are regent street, oxford street and what else?                                                                              \n",
      "Input to placeholder classifier \n",
      " the green coloured are regent street, oxford and what else?                                                                                        \n",
      "Expected placeholder classifier output \n",
      "  <PLH> <PLH> <PLH>the green coloured are <PLH>regent street, oxford and what <PLH>else?                                                                                        \n",
      "Input to insertion classifier \n",
      "  <PLH> <PLH> <PLH>the green coloured <PLH>are regent street, oxford <PLH>and what else?                                                                                   \n",
      "Expected insertion classifier output \n",
      " in monopoly, the green coloured properties are regent street, oxford street and what else?                                                                                   \n",
      "150\n",
      "tensor(2.7093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " \" what jersey is awarded to the \" \" king of the hill \" \", the best climber in the tour de france? \"                                                                         \n",
      "Ground truth post-deletion \n",
      " what jersey is awarded to the \" \" king of the \", bester the tour de france?                                                                                \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " what jersey is awarded to the \" \" king of the \", bester the tour de france?                                                                                \n",
      "Post-placeholders \n",
      " what jersey is awarded to the \" \" king of the \", bester the tour de france?                                                                                \n",
      "Post-insert \n",
      " what jersey is awarded to the \" \" king of the \", bester the tour de france?                                                                                \n",
      "what jersey is awarded to the \" \" king of the \", bester the tour de france? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "175\n",
      "Ground \n",
      " who directed the 2010 psychological thriller'shutter island ', starring leonardo di caprio?                                                                                   \n",
      "Input to deletion classifier \n",
      " who directed the 2010 psychological thriller 'shutter island  ',  starring leonardo di  caprio ?                                                                              \n",
      "Expected deletion classifier output \n",
      " who directed the 2010 psychological thriller'shutter island ', starring leonardo di caprio?                                                                              \n",
      "Input to placeholder classifier \n",
      " who directed psychological'shutter island leonardo di caprio?                                                                                         \n",
      "Expected placeholder classifier output \n",
      " who directed <PLH> <PLH>psychological'<PLH>shutter island leonardo di <PLH> <PLH> <PLH>caprio?                                                                                         \n",
      "Input to insertion classifier \n",
      " who directed <PLH> <PLH>psychological <PLH>' shutter island <PLH> <PLH> <PLH>leonardo di caprio?                                                                                   \n",
      "Expected insertion classifier output \n",
      " who directed the 2010 psychological thriller'shutter island ', starring leonardo di caprio?                                                                                   \n",
      "200\n",
      "Ground \n",
      " what were the weapons used mainly by infantrymen in the american civil war?                                                                                     \n",
      "Input to deletion classifier \n",
      " what were the weapons used mainly by infantrymen in  the american civil war?                                                                                    \n",
      "Expected deletion classifier output \n",
      " what were the weapons used mainly by infantrymen in the american civil war?                                                                                  \n",
      "Input to placeholder classifier \n",
      " what the used by infantrymen the civil war?                                                                                          \n",
      "Expected placeholder classifier output \n",
      " what <PLH>the used <PLH>by infantry <PLH>##men the civil war <PLH>?  <PLH>                                                                                        \n",
      "Input to insertion classifier \n",
      " what <PLH>the <PLH>used <PLH>by infantrymen <PLH>the <PLH>civil war?                                                                                     \n",
      "Expected insertion classifier output \n",
      " what were the weapons used mainly by infantrymen in the american civil war?                                                                                     \n",
      "200\n",
      "tensor(2.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " which north american state has the nickname the badger state?                                                                                         \n",
      "Ground truth post-deletion \n",
      " which american state has the nickname badger state                                                                                            \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " which american state has the nickname badger state                                                                                            \n",
      "Post-placeholders \n",
      " which american state has the nickname badger state                                                                                            \n",
      "Post-insert \n",
      " which american state has the nickname badger state                                                                                            \n",
      "which american state has the nickname badger state [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "225\n",
      "Ground \n",
      " which instrument is played by classical musician john lill?                                                                                         \n",
      "Input to deletion classifier \n",
      "  which instrument is played by classical  musician john lil l?                                                                                      \n",
      "Expected deletion classifier output \n",
      " which instrument is played by classical musician john lill?                                                                                     \n",
      "Input to placeholder classifier \n",
      " instrument is played classical musician john lill?                                                                                           \n",
      "Expected placeholder classifier output \n",
      "  <PLH>instrument is played classical <PLH>musician john lill?                                                                                           \n",
      "Input to insertion classifier \n",
      "  <PLH>instrument is played <PLH>classical musician john lill?                                                                                         \n",
      "Expected insertion classifier output \n",
      " which instrument is played by classical musician john lill?                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "Ground \n",
      " which branch of astronomy studies radiation with wavelengths greater than approximately one millimetre?                                                                                    \n",
      "Input to deletion classifier \n",
      " which branch  of astronomy  studies radiation with wavelengths greater  than approximately  one mill imetre?                                                                               \n",
      "Expected deletion classifier output \n",
      " which branch of astronomy studies radiation with wavelengths greater than approximately one millimetre?                                                                               \n",
      "Input to placeholder classifier \n",
      " which branch studies with wavelengths greater than one mill?                                                                                          \n",
      "Expected placeholder classifier output \n",
      " which branch <PLH> <PLH>studies with <PLH>wavelengths greater than one mill <PLH>?   <PLH> <PLH>                                                                                       \n",
      "Input to insertion classifier \n",
      " which branch <PLH> <PLH>studies <PLH>with wavelengths greater than <PLH>one mill <PLH> <PLH>?                                                                                    \n",
      "Expected insertion classifier output \n",
      " which branch of astronomy studies radiation with wavelengths greater than approximately one millimetre?                                                                                    \n",
      "250\n",
      "tensor(2.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " what gift is presented to'prince tamino'in the title of a mozart opera?                                                                                  \n",
      "Ground truth post-deletion \n",
      " gift is presented to'prince tamino'title of mozart                                                                                        \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " gift is presented to'prince tamino'title of mozart                                                                                        \n",
      "Post-placeholders \n",
      " gift is presented to'prince tamino'title of mozart                                                                                        \n",
      "Post-insert \n",
      " gift is presented to'prince tamino'title of mozart                                                                                        \n",
      "gift is presented to'prince tamino'title of mozart [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "275\n",
      "Ground \n",
      " what was the usa's biggest attack of the vietnam war when it took place in february 1967?                                                                                \n",
      "Input to deletion classifier \n",
      " what  was the  usa's biggest attack of  the vietnam war when it took  place in february 1967 ?                                                                           \n",
      "Expected deletion classifier output \n",
      " what was the usa's biggest attack of the vietnam war when it took place in february 1967?                                                                           \n",
      "Input to placeholder classifier \n",
      " what was the usa's attack the vietnam war it took place in february 1967?                                                                                   \n",
      "Expected placeholder classifier output \n",
      " what was the usa's <PLH>attack the <PLH>vietnam war it took <PLH>place in february 1967?                                                                                   \n",
      "Input to insertion classifier \n",
      " what was the usa's <PLH>attack <PLH>the vietnam war <PLH>it took place in february 1967?                                                                                \n",
      "Expected insertion classifier output \n",
      " what was the usa's biggest attack of the vietnam war when it took place in february 1967?                                                                                \n",
      "300\n",
      "Ground \n",
      " on 29 march 1971, lieutenant william calley was found guilty by a court martial for murdering 20 civilians in 1968 - where?                                                                           \n",
      "Input to deletion classifier \n",
      " on 29 march 1971, lieutenant william calley was  found guilty  by a court  martial for  murdering 20 civilians in  1968 - where?                                                                      \n",
      "Expected deletion classifier output \n",
      " on 29 march 1971, lieutenant william calley was found guilty by a court martial for murdering 20 civilians in 1968 - where?                                                                      \n",
      "Input to placeholder classifier \n",
      " on 1971 william calley was found guilty by a court martial for murdering civilians in 1968 -                                                                                  \n",
      "Expected placeholder classifier output \n",
      " on <PLH> <PLH>1971 william <PLH> <PLH>calley was found guilty by a court martial for murdering civilians in <PLH>1968 -    <PLH> <PLH>                                                                              \n",
      "Input to insertion classifier \n",
      " on <PLH> <PLH>1971 <PLH> <PLH>william calley was found guilty by a court martial for murdering <PLH>civilians in 1968 - <PLH> <PLH>                                                                          \n",
      "Expected insertion classifier output \n",
      " on 29 march 1971, lieutenant william calley was found guilty by a court martial for murdering 20 civilians in 1968 - where?                                                                           \n",
      "300\n",
      "tensor(2.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " what las vegas hotel is shaped like an egyptian pyramid?                                                                                         \n",
      "Ground truth post-deletion \n",
      " what hotel is shaped like an egyptian pyramid?                                                                                           \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " what hotel is shaped like an egyptian pyramid?                                                                                           \n",
      "Post-placeholders \n",
      " what hotel is shaped like an egyptian pyramid?                                                                                           \n",
      "Post-insert \n",
      " what hotel is shaped like an egyptian pyramid?                                                                                           \n",
      "what hotel is shaped like an egyptian pyramid? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "325\n",
      "Ground \n",
      " the galapagos islands are subject to continuing volcanic activity, and are situated where in relation to tectonic plates?                                                                            \n",
      "Input to deletion classifier \n",
      "  the galapagos islands  are subject  to continuing volcanic activity , and are situated where in  relation to tectonic plates?                                                                       \n",
      "Expected deletion classifier output \n",
      " the galapagos islands are subject to continuing volcanic activity, and are situated where in relation to tectonic plates?                                                                       \n",
      "Input to placeholder classifier \n",
      " thegos islands are subject volcanic activity, and are situated where in relation to tectonic                                                                                  \n",
      "Expected placeholder classifier output \n",
      " the <PLH> <PLH>##gos islands are subject volcanic <PLH> <PLH>activity, and are situated where in relation to tectonic   <PLH> <PLH>                                                                               \n",
      "Input to insertion classifier \n",
      " the <PLH> <PLH>##gos islands are subject <PLH> <PLH>volcanic activity, and are situated where in relation to tectonic <PLH> <PLH>                                                                           \n",
      "Expected insertion classifier output \n",
      " the galapagos islands are subject to continuing volcanic activity, and are situated where in relation to tectonic plates?                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "Ground \n",
      " what type of rock is formed by the solidification of molten magma?                                                                                      \n",
      "Input to deletion classifier \n",
      " what  type of rock is  formed by the solidification of molten magma ?                                                                                   \n",
      "Expected deletion classifier output \n",
      " what type of rock is formed by the solidification of molten magma?                                                                                   \n",
      "Input to placeholder classifier \n",
      " type of is formed byification molten?                                                                                            \n",
      "Expected placeholder classifier output \n",
      "  <PLH>type of is <PLH>formed byification molten <PLH> <PLH>?  <PLH>  <PLH>                                                                                        \n",
      "Input to insertion classifier \n",
      "  <PLH>type of <PLH>is formed by <PLH> <PLH>##ification <PLH>molten <PLH>?                                                                                      \n",
      "Expected insertion classifier output \n",
      " what type of rock is formed by the solidification of molten magma?                                                                                      \n",
      "350\n",
      "tensor(2.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " what are grapnel, bruce, kedge, and plough                                                                                      \n",
      "Ground truth post-deletion \n",
      " what are gr, bruce ked,                                                                                             \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " what are gr, bruce ked,                                                                                             \n",
      "Post-placeholders \n",
      " what are gr, bruce ked,                                                                                             \n",
      "Post-insert \n",
      " what are gr, bruce ked,                                                                                             \n",
      "what are gr, bruce ked, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "375\n",
      "Ground \n",
      " what rejection is shared by ls lowry, john lennon ; philip larkin, benjamin zephaniah, and danny boyle? chivalric order ; us - visa ; blood donation ; or driving licence?                                                           \n",
      "Input to deletion classifier \n",
      " what rejection is shared by ls  lowry, john lennon  ; philip larkin,  benjamin ze phania h, and danny boyle? chivalric order ; us - visa ; blood donation ; or driving licence?                                                      \n",
      "Expected deletion classifier output \n",
      " what rejection is shared by ls lowry, john lennon ; philip larkin, benjamin zephaniah, and danny boyle? chivalric order ; us - visa ; blood donation ; or driving licence?                                                      \n",
      "Input to placeholder classifier \n",
      " what is shared by ls lowry, john lennon ; larkin, zephah, and boyle? chiric order ; us - visa ; donation or driving licence?                                                                   \n",
      "Expected placeholder classifier output \n",
      " what <PLH>is shared by ls lowry, john lennon ; larkin <PLH>, zepha <PLH>##h, and <PLH>boyle? chiric <PLH>order ; us - <PLH>visa ; donation or driving licence?  <PLH>  <PLH>                                                               \n",
      "Input to insertion classifier \n",
      " what <PLH>is shared by ls lowry, john lennon ; <PLH>larkin, <PLH>zepha <PLH>##h, and <PLH>boyle? chi <PLH>##ric order ; us - visa ; <PLH>donation <PLH>or driving licence?                                                           \n",
      "Expected insertion classifier output \n",
      " what rejection is shared by ls lowry, john lennon ; philip larkin, benjamin zephaniah, and danny boyle? chivalric order ; us - visa ; blood donation ; or driving licence?                                                           \n",
      "400\n",
      "Ground \n",
      " in  othello , to whom is emilia, desdemona  s maidservant, married?                                                                             \n",
      "Input to deletion classifier \n",
      "  in  othello , to whom is  emilia, desdemona  s maidservant, married?                                                                           \n",
      "Expected deletion classifier output \n",
      " in  othello , to whom is emilia, desdemona  s maidservant, married?                                                                           \n",
      "Input to placeholder classifier \n",
      " in hello , whom, desde  s maidservant married?                                                                                   \n",
      "Expected placeholder classifier output \n",
      " in  <PLH>##hello , whom <PLH>, des <PLH> <PLH>##de  s maids <PLH>##ervant married?   <PLH>                                                                                \n",
      "Input to insertion classifier \n",
      " in  <PLH>##hello , <PLH>whom <PLH> <PLH>, desde <PLH> s maidservant <PLH>married?                                                                             \n",
      "Expected insertion classifier output \n",
      " in  othello , to whom is emilia, desdemona  s maidservant, married?                                                                             \n",
      "400\n",
      "tensor(2.5884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " which country, a member of the eu, produces the rich dessert wine commandaria?                                                                                   \n",
      "Ground truth post-deletion \n",
      " which country a of the eu, produces the rich dessert wine command?                                                                                      \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " which country a of the eu, produces the rich dessert wine command?                                                                                      \n",
      "Post-placeholders \n",
      " which country a of the eu, produces the rich dessert wine command?                                                                                      \n",
      "Post-insert \n",
      " which country a of the eu, produces the rich dessert wine command?                                                                                      \n",
      "which country a of the eu, produces the rich dessert wine command? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "425\n",
      "Ground \n",
      " in which year was the euro, the single european currency, introduced into the world financial markets?                                                                                 \n",
      "Input to deletion classifier \n",
      "  in which  year was the euro,  the single european  currency,  introduced into the world financial markets?                                                                            \n",
      "Expected deletion classifier output \n",
      " in which year was the euro, the single european currency, introduced into the world financial markets?                                                                            \n",
      "Input to placeholder classifier \n",
      " in which year was the euro, single european currency, introduced into the world financial?                                                                                   \n",
      "Expected placeholder classifier output \n",
      " in which year was the euro, <PLH>single european currency, introduced into the world financial? <PLH>                                                                                  \n",
      "Input to insertion classifier \n",
      " in which year was the euro, <PLH>single european currency, introduced into the world financial <PLH>?                                                                                 \n",
      "Expected insertion classifier output \n",
      " in which year was the euro, the single european currency, introduced into the world financial markets?                                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "Ground \n",
      " hanoi is the capital of which country?                                                                                            \n",
      "Input to deletion classifier \n",
      " hanoi is  the capital  of which country?                                                                                          \n",
      "Expected deletion classifier output \n",
      " hanoi is the capital of which country?                                                                                         \n",
      "Input to placeholder classifier \n",
      " is the of?                                                                                                \n",
      "Expected placeholder classifier output \n",
      "  <PLH>is the of <PLH>?  <PLH> <PLH>                                                                                              \n",
      "Input to insertion classifier \n",
      "  <PLH>is the <PLH>of <PLH> <PLH>?                                                                                            \n",
      "Expected insertion classifier output \n",
      " hanoi is the capital of which country?                                                                                            \n",
      "450\n",
      "tensor(2.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " who plays captain kirk in the 2013 star trek film?                                                                                         \n",
      "Ground truth post-deletion \n",
      " who plays captain in 2013 star trek film                                                                                            \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " who plays captain in 2013 star trek film                                                                                            \n",
      "Post-placeholders \n",
      " who plays captain in 2013 star trek film                                                                                            \n",
      "Post-insert \n",
      " who plays captain in 2013 star trek film                                                                                            \n",
      "who plays captain in 2013 star trek film [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "475\n",
      "Ground \n",
      " the bummalo fish is better known by what name?                                                                                        \n",
      "Input to deletion classifier \n",
      " the  bummalo  fish is better known  by what name?                                                                                     \n",
      "Expected deletion classifier output \n",
      " the bummalo fish is better known by what name?                                                                                    \n",
      "Input to placeholder classifier \n",
      " themalo is better known by what name                                                                                           \n",
      "Expected placeholder classifier output \n",
      " the <PLH>##malo is <PLH>better known by what name   <PLH>                                                                                        \n",
      "Input to insertion classifier \n",
      " the <PLH>##malo <PLH>is better known by what name <PLH>                                                                                       \n",
      "Expected insertion classifier output \n",
      " the bummalo fish is better known by what name?                                                                                        \n",
      "500\n",
      "Ground \n",
      " for which club did roy of the rovers play?                                                                                          \n",
      "Input to deletion classifier \n",
      " for which  club did roy of  the rovers play ?                                                                                       \n",
      "Expected deletion classifier output \n",
      " for which club did roy of the rovers play?                                                                                     \n",
      "Input to placeholder classifier \n",
      " for which club did roy of the rovers play?                                                                                          \n",
      "Expected placeholder classifier output \n",
      " for which club did roy of the rovers play?                                                                                          \n",
      "Input to insertion classifier \n",
      " for which club did roy of the rovers play?                                                                                          \n",
      "Expected insertion classifier output \n",
      " for which club did roy of the rovers play?                                                                                          \n",
      "500\n",
      "tensor(2.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " who became the world chess champion after beating boris spassky in 1972?                                                                                     \n",
      "Ground truth post-deletion \n",
      " who became the world chess champion borisssky in 1972?                                                                                        \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " who became the world chess champion borisssky in 1972?                                                                                        \n",
      "Post-placeholders \n",
      " who became the world chess champion borisssky in 1972?                                                                                        \n",
      "Post-insert \n",
      " who became the world chess champion borisssky in 1972?                                                                                        \n",
      "who became the world chess champion borisssky in 1972? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "525\n",
      "Ground \n",
      " zine el abidine ben ali became president of which african country in november 1987?                                                                                  \n",
      "Input to deletion classifier \n",
      " z ine el abidine ben ali became president of which african country  in november 1987?                                                                                \n",
      "Expected deletion classifier output \n",
      " zine el abidine ben ali became president of which african country in november 1987?                                                                                \n",
      "Input to placeholder classifier \n",
      " zine abidine ben became of which african country november 1987?                                                                                      \n",
      "Expected placeholder classifier output \n",
      " zine <PLH>abidine ben became <PLH>of which <PLH>african country november 1987? <PLH>                                                                                     \n",
      "Input to insertion classifier \n",
      " zine <PLH>abidine ben <PLH>became <PLH>of which african country <PLH>november 1987?                                                                                  \n",
      "Expected insertion classifier output \n",
      " zine el abidine ben ali became president of which african country in november 1987?                                                                                  \n",
      "550\n",
      "Ground \n",
      " different from the flags used by the officials, what color flag is used by nfl football coaches to challenge the ruling on the field?                                                                          \n",
      "Input to deletion classifier \n",
      " different from the flags used by the officials, what color  flag is  used by nfl football  coaches to challenge the ruling  on the field?                                                                      \n",
      "Expected deletion classifier output \n",
      " different from the flags used by the officials, what color flag is used by nfl football coaches to challenge the ruling on the field?                                                                     \n",
      "Input to placeholder classifier \n",
      " different from the flags used by the officials what color is used by nfl football coaches to challenge the ruling on the?                                                                             \n",
      "Expected placeholder classifier output \n",
      " different from the flags used by the officials <PLH>what color is <PLH>used by nfl football coaches to challenge the ruling on the?  <PLH>                                                                           \n",
      "Input to insertion classifier \n",
      " different from the flags used by the officials <PLH>what color <PLH>is used by nfl football coaches to challenge the ruling on the <PLH>?                                                                          \n",
      "Expected insertion classifier output \n",
      " different from the flags used by the officials, what color flag is used by nfl football coaches to challenge the ruling on the field?                                                                          \n",
      "550\n",
      "tensor(2.0135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " which horse won the aintree grand national in 2015?                                                                                         \n",
      "Ground truth post-deletion \n",
      " won thetree grand national in 2015?                                                                                            \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " won thetree grand national in 2015?                                                                                            \n",
      "Post-placeholders \n",
      " won thetree grand national in 2015?                                                                                            \n",
      "Post-insert \n",
      " won thetree grand national in 2015?                                                                                            \n",
      "won thetree grand national in 2015? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575\n",
      "Ground \n",
      " emma thompson won the best actress oscar in 1993 for a role in which film?                                                                                    \n",
      "Input to deletion classifier \n",
      " emma  thompson won the best actress  oscar in 1993 for a role in which film?                                                                                  \n",
      "Expected deletion classifier output \n",
      " emma thompson won the best actress oscar in 1993 for a role in which film?                                                                                 \n",
      "Input to placeholder classifier \n",
      " emma thompson won the best actress oscar in 1993 for a role in which film                                                                                     \n",
      "Expected placeholder classifier output \n",
      " emma thompson won the best actress oscar in 1993 for a role in which film <PLH>                                                                                    \n",
      "Input to insertion classifier \n",
      " emma thompson won the best actress oscar in 1993 for a role in which film <PLH>                                                                                   \n",
      "Expected insertion classifier output \n",
      " emma thompson won the best actress oscar in 1993 for a role in which film?                                                                                    \n",
      "600\n",
      "Ground \n",
      " what is the capital of the central italian region of umbria?                                                                                       \n",
      "Input to deletion classifier \n",
      " what is the capital  of the central italian  region of  umbria?                                                                                    \n",
      "Expected deletion classifier output \n",
      " what is the capital of the central italian region of umbria?                                                                                   \n",
      "Input to placeholder classifier \n",
      " what the capital the central italian?                                                                                             \n",
      "Expected placeholder classifier output \n",
      " what <PLH>the capital the <PLH>central italian?  <PLH> <PLH> <PLH> <PLH>                                                                                           \n",
      "Input to insertion classifier \n",
      " what <PLH>the capital <PLH>the central italian <PLH> <PLH> <PLH> <PLH>?                                                                                       \n",
      "Expected insertion classifier output \n",
      " what is the capital of the central italian region of umbria?                                                                                       \n",
      "600\n",
      "tensor(2.0431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " what is the capital of somalia?                                                                                             \n",
      "Ground truth post-deletion \n",
      " what is capital of somalia                                                                                               \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " what is capital of somalia                                                                                               \n",
      "Post-placeholders \n",
      " what is capital of somalia                                                                                               \n",
      "Post-insert \n",
      " what is capital of somalia                                                                                               \n",
      "what is capital of somalia [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "625\n",
      "Ground \n",
      " giacomo agostini was seven times world champion between 1966 and 1972 in which sport?                                                                                   \n",
      "Input to deletion classifier \n",
      " giacomo  agostini was seven times  world champion  between 1966 and 1972 in which sport?                                                                                \n",
      "Expected deletion classifier output \n",
      " giacomo agostini was seven times world champion between 1966 and 1972 in which sport?                                                                                \n",
      "Input to placeholder classifier \n",
      " giacomo agoni was seven times world champion between and 1972 in which?                                                                                      \n",
      "Expected placeholder classifier output \n",
      " giacomo ago <PLH>##ni was seven times world champion between and <PLH>1972 in which?  <PLH>                                                                                    \n",
      "Input to insertion classifier \n",
      " giacomo ago <PLH>##ni was seven times world champion between <PLH>and 1972 in which <PLH>?                                                                                   \n",
      "Expected insertion classifier output \n",
      " giacomo agostini was seven times world champion between 1966 and 1972 in which sport?                                                                                   \n",
      "650\n",
      "Ground \n",
      " the novel'dead souls'and the play'the government inspector'are two of the best known works of which russian author?                                                                          \n",
      "Input to deletion classifier \n",
      "  the novel 'dead souls'and  the play'the government inspector'are two of the best known works  of which russian author?                                                                      \n",
      "Expected deletion classifier output \n",
      " the novel'dead souls'and the play'the government inspector'are two of the best known works of which russian author?                                                                     \n",
      "Input to placeholder classifier \n",
      " novel'dead'and the play'the inspector are two of best works of which russian author?                                                                                \n",
      "Expected placeholder classifier output \n",
      "  <PLH>novel'dead'<PLH>and the play'the inspector are <PLH>two of <PLH>best works of which <PLH>russian author <PLH>?                                                                                \n",
      "Input to insertion classifier \n",
      "  <PLH>novel'dead <PLH>' and the play'the <PLH>inspector <PLH>are two of <PLH>best <PLH>works of which russian author?                                                                          \n",
      "Expected insertion classifier output \n",
      " the novel'dead souls'and the play'the government inspector'are two of the best known works of which russian author?                                                                          \n",
      "650\n",
      "tensor(2.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " which world - famous song was originally entitled  good morning to all ?                                                                                     \n",
      "Ground truth post-deletion \n",
      " which - famous song was originally entitled good to all ?                                                                                        \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " which - famous song was originally entitled good to all ?                                                                                        \n",
      "Post-placeholders \n",
      " which - famous song was originally entitled good to all ?                                                                                        \n",
      "Post-insert \n",
      " which - famous song was originally entitled good to all ?                                                                                        \n",
      "which - famous song was originally entitled good to all ? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675\n",
      "Ground \n",
      " \" what was greta garbo's first sound film ( advertised as \" \" garbo speaks! \" \" ), in a filmed version of a play by eugene o'neill? \"                                                            \n",
      "Input to deletion classifier \n",
      " \" what was greta ga rbo's first sound  film ( advertised as \"  \" ga rbo speaks ! \" \" ), in a filmed version of a play by eugene o'neill? \"                                                       \n",
      "Expected deletion classifier output \n",
      " \" what was greta garbo's first sound film ( advertised as \" \" garbo speaks! \" \" ), in a filmed version of a play by eugene o'neill? \"                                                       \n",
      "Input to placeholder classifier \n",
      " \" what was gretarbo's first sound film ( advertised as \" garbo speaks! \" ), in a filmed version of a play by eugene'neill?                                                                 \n",
      "Expected placeholder classifier output \n",
      " \" what was greta <PLH>##rbo's first sound film ( advertised as \" ga <PLH>##rbo speaks! \" ), <PLH>in a filmed version of a play by eugene'neill? <PLH>    <PLH>                                                            \n",
      "Input to insertion classifier \n",
      " \" what was greta <PLH>##rbo's first sound film ( advertised as \" <PLH>garbo speaks! \" <PLH>), in a filmed version of a play by eugene <PLH>' neill? <PLH>                                                           \n",
      "Expected insertion classifier output \n",
      " \" what was greta garbo's first sound film ( advertised as \" \" garbo speaks! \" \" ), in a filmed version of a play by eugene o'neill? \"                                                            \n",
      "700\n",
      "Ground \n",
      " which lake was created by the construction of the aswan high dam?                                                                                      \n",
      "Input to deletion classifier \n",
      " which  lake was created by the construction  of the aswan high  dam?                                                                                   \n",
      "Expected deletion classifier output \n",
      " which lake was created by the construction of the aswan high dam?                                                                                  \n",
      "Input to placeholder classifier \n",
      " which lake by the construction of thewan high dam?                                                                                         \n",
      "Expected placeholder classifier output \n",
      " which lake <PLH> <PLH>by the construction of thewan <PLH>high dam?                                                                                         \n",
      "Input to insertion classifier \n",
      " which lake <PLH> <PLH>by the construction of the <PLH>##wan high dam?                                                                                      \n",
      "Expected insertion classifier output \n",
      " which lake was created by the construction of the aswan high dam?                                                                                      \n",
      "700\n",
      "tensor(2.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " \" the first editions of lewis carroll's \" \" alice... \" \" books were given a special flavour by illustrations by which 19th century graphic humourist and political cartoonist? \"                                                               \n",
      "Ground truth post-deletion \n",
      " \" editions \" \" alice.. \" \" books were given a special flavour illustrations which 19th century graphicist and \"                                                                             \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " \" editions \" \" alice.. \" \" books were given a special flavour illustrations which 19th century graphicist and \"                                                                             \n",
      "Post-placeholders \n",
      " \" editions \" \" alice.. \" \" books were given a special flavour illustrations which 19th century graphicist and \"                                                                             \n",
      "Post-insert \n",
      " \" editions \" \" alice.. \" \" books were given a special flavour illustrations which 19th century graphicist and \"                                                                             \n",
      "\" editions \" \" alice.. \" \" books were given a special flavour illustrations which 19th century graphicist and \" [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "725\n",
      "Ground \n",
      " the 1999 film 10 things i hate about you starring julia stiles and heath ledger is based on which of shakespeare's plays?                                                                          \n",
      "Input to deletion classifier \n",
      " the 1999 film 10 things  i hate about you  starring julia stiles and heath ledger is based on  which of shakespeare's plays ?                                                                      \n",
      "Expected deletion classifier output \n",
      " the 1999 film 10 things i hate about you starring julia stiles and heath ledger is based on which of shakespeare's plays?                                                                      \n",
      "Input to placeholder classifier \n",
      " 1999 film 10 things i about stiles and heath based on of shakespeare's plays?                                                                                  \n",
      "Expected placeholder classifier output \n",
      "  <PLH>1999 film 10 things i about <PLH>stiles <PLH> <PLH> <PLH>and heath based on of <PLH> <PLH>shakespeare's <PLH>plays?                                                                                  \n",
      "Input to insertion classifier \n",
      "  <PLH>1999 film 10 things i <PLH>about <PLH> <PLH> <PLH>stiles and heath <PLH> <PLH>based on <PLH>of shakespeare's plays?                                                                          \n",
      "Expected insertion classifier output \n",
      " the 1999 film 10 things i hate about you starring julia stiles and heath ledger is based on which of shakespeare's plays?                                                                          \n",
      "750\n",
      "Ground \n",
      " according to greek mythology, what son of daedalus donned wings of feathers and wax, and promptly flew too close to the son, causing the wax to melt and his ultimate drowning, having fallen from the sky into the sea?                                                     \n",
      "Input to deletion classifier \n",
      "  according to greek mythology, what son  of daedalus don ned wings  of feathers and wax,  and promptly flew too close to the son, causing the wax to melt and his ultimate drowning, having fallen from the sky into the sea?                                                \n",
      "Expected deletion classifier output \n",
      " according to greek mythology, what son of daedalus donned wings of feathers and wax, and promptly flew too close to the son, causing the wax to melt and his ultimate drowning, having fallen from the sky into the sea?                                                \n",
      "Input to placeholder classifier \n",
      " according to, of daedalus feathers and, promptly flew too close the son, causing the wax melt ultimate having fallen from the sky into?                                                                       \n",
      "Expected placeholder classifier output \n",
      " according to <PLH> <PLH>, of <PLH> <PLH>daedalus feathers and <PLH> <PLH> <PLH> <PLH>, promptly flew <PLH>too close <PLH>the son, causing the <PLH>wax melt ultimate having fallen from the <PLH>sky into <PLH> <PLH>?  <PLH> <PLH>       <PLH> <PLH>                                                              \n",
      "Input to insertion classifier \n",
      " according to <PLH> <PLH>, <PLH> <PLH>of daedalus <PLH> <PLH> <PLH> <PLH>feathers and <PLH>, <PLH>promptly flew too close <PLH>the son, causing the wax <PLH>melt <PLH> <PLH>ultimate <PLH> <PLH>having fallen from the sky into <PLH> <PLH>?                                                     \n",
      "Expected insertion classifier output \n",
      " according to greek mythology, what son of daedalus donned wings of feathers and wax, and promptly flew too close to the son, causing the wax to melt and his ultimate drowning, having fallen from the sky into the sea?                                                     \n",
      "750\n",
      "tensor(2.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " in heraldry, what does'sinister'mean?                                                                                         \n",
      "Ground truth post-deletion \n",
      " in heraldry does'                                                                                              \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " in heraldry does'                                                                                              \n",
      "Post-placeholders \n",
      " in heraldry does'                                                                                              \n",
      "Post-insert \n",
      " in heraldry does'                                                                                              \n",
      "in heraldry does'[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775\n",
      "Ground \n",
      " what region of china that has a border checkpoint called posto fronteirico das portas do cerco ('frontier post of the border gate'in portuguese ) is both the first and last european colony in that country?                                                      \n",
      "Input to deletion classifier \n",
      " what region  of china  that has a border checkpoint called  posto front eirico das port as do cerco ('frontier post of the border gate'in portuguese ) is both the first and last european colony in that country?                                                 \n",
      "Expected deletion classifier output \n",
      " what region of china that has a border checkpoint called posto fronteirico das portas do cerco ('frontier post of the border gate'in portuguese ) is both the first and last european colony in that country?                                                 \n",
      "Input to placeholder classifier \n",
      " what of has border checkpoint postoeirico das portas do ('frontier of border gate in portuguese both first european colony in that country?                                                                      \n",
      "Expected placeholder classifier output \n",
      " what <PLH>of has <PLH> <PLH>border checkpoint <PLH>postoei <PLH>##rico das <PLH>portas do ('frontier of border <PLH> <PLH>gate in portuguese both <PLH>first european <PLH>colony in that <PLH>country?  <PLH> <PLH>  <PLH>  <PLH> <PLH>                                                                \n",
      "Input to insertion classifier \n",
      " what <PLH>of <PLH> <PLH>has <PLH>border checkpoint <PLH>posto <PLH>##eirico das portas do <PLH> <PLH>('frontier <PLH>of <PLH>border gate <PLH>in portuguese <PLH> <PLH>both <PLH>first <PLH> <PLH>european colony in that country?                                                      \n",
      "Expected insertion classifier output \n",
      " what region of china that has a border checkpoint called posto fronteirico das portas do cerco ('frontier post of the border gate'in portuguese ) is both the first and last european colony in that country?                                                      \n",
      "800\n",
      "Ground \n",
      " what was the nickname of the american serial killer john wayne gacy who was executed in 1994 for the rape and murder of 33 boys and young men?                                                                      \n",
      "Input to deletion classifier \n",
      " what  was the  nickname of  the american serial killer john  wayne gacy who was executed in 1994 for the  rape and murder of 33 boys and young men?                                                                 \n",
      "Expected deletion classifier output \n",
      " what was the nickname of the american serial killer john wayne gacy who was executed in 1994 for the rape and murder of 33 boys and young men?                                                                 \n",
      "Input to placeholder classifier \n",
      " the nickname of american john wayne gacy who was executed in 1994 for the rape murder of 33 boys and young?                                                                             \n",
      "Expected placeholder classifier output \n",
      "  <PLH> <PLH>the nickname of american <PLH>john wayne <PLH> <PLH>gacy who was executed in 1994 for the rape murder of 33 <PLH>boys and young?    <PLH>                                                                         \n",
      "Input to insertion classifier \n",
      "  <PLH> <PLH>the nickname of <PLH>american <PLH> <PLH>john wayne gacy who was executed in 1994 for the rape <PLH>murder of 33 boys and young <PLH>?                                                                      \n",
      "Expected insertion classifier output \n",
      " what was the nickname of the american serial killer john wayne gacy who was executed in 1994 for the rape and murder of 33 boys and young men?                                                                      \n",
      "800\n",
      "tensor(2.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " which english singer released an 2004 album entitled  unwritten ?                                                                                       \n",
      "Ground truth post-deletion \n",
      " which english singer released an album entitled  un?                                                                                          \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " which english singer released an album entitled  un?                                                                                          \n",
      "Post-placeholders \n",
      " which english singer released an album entitled  un?                                                                                          \n",
      "Post-insert \n",
      " which english singer released an album entitled  un?                                                                                          \n",
      "which english singer released an album entitled  un? [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "825\n",
      "Ground \n",
      " according to the wwii propaganda poster, what might loose lips do?                                                                                       \n",
      "Input to deletion classifier \n",
      " according to the wwii propaganda poster, what might loose  lips do ?                                                                                     \n",
      "Expected deletion classifier output \n",
      " according to the wwii propaganda poster, what might loose lips do?                                                                                     \n",
      "Input to placeholder classifier \n",
      " according to the wwii propaganda, what might loose lips do?                                                                                        \n",
      "Expected placeholder classifier output \n",
      " according to the wwii propaganda <PLH>, what might loose lips do?                                                                                        \n",
      "Input to insertion classifier \n",
      " according to the wwii propaganda <PLH>, what might loose lips do?                                                                                       \n",
      "Expected insertion classifier output \n",
      " according to the wwii propaganda poster, what might loose lips do?                                                                                       \n",
      "850\n",
      "Ground \n",
      " which'palace'is located in muswell hill, london?                                                                                       \n",
      "Input to deletion classifier \n",
      " which' palace'is located in muswell hill, london?                                                                                      \n",
      "Expected deletion classifier output \n",
      " which'palace'is located in muswell hill, london?                                                                                     \n",
      "Input to placeholder classifier \n",
      " which'' is in mu hill,                                                                                            \n",
      "Expected placeholder classifier output \n",
      " which'<PLH>' is in <PLH>mu hill, <PLH>   <PLH> <PLH>                                                                                        \n",
      "Input to insertion classifier \n",
      " which'<PLH>' is <PLH>in mu <PLH>hill, <PLH> <PLH>                                                                                      \n",
      "Expected insertion classifier output \n",
      " which'palace'is located in muswell hill, london?                                                                                       \n",
      "850\n",
      "tensor(2.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Ground truth \n",
      " who were manchester utd's opponents in january 1948, when the highest ever attendance at a football league match was recorded?                                                                           \n",
      "Ground truth post-deletion \n",
      " were manchesterd'opponents january 1948 when the highest attendance at football match recorded                                                                                     \n",
      "Decode step 0\n",
      "Post-deletion \n",
      " were manchesterd'opponents january 1948 when the highest attendance at football match recorded                                                                                     \n",
      "Post-placeholders \n",
      " were manchesterd'opponents january 1948 when the highest attendance at football match recorded                                                                                     \n",
      "Post-insert \n",
      " were manchesterd'opponents january 1948 when the highest attendance at football match recorded                                                                                     \n",
      "were manchesterd'opponents january 1948 when the highest attendance at football match recorded [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875\n",
      "Ground \n",
      " the tragic videoed killing of neda agha - soltan became iconic following what city's demonstrations?                                                                              \n",
      "Input to deletion classifier \n",
      " the tragic videoed killing of neda  agha - soltan  became iconic following what city's demonstrations?                                                                            \n",
      "Expected deletion classifier output \n",
      " the tragic videoed killing of neda agha - soltan became iconic following what city's demonstrations?                                                                            \n",
      "Input to placeholder classifier \n",
      " the tragic videoed killing of nedaha - soltan became iconic what city's demonstrations?                                                                                \n",
      "Expected placeholder classifier output \n",
      " the tragic videoed killing of neda <PLH>##ha - soltan became iconic what <PLH>city's demonstrations?                                                                                \n",
      "Input to insertion classifier \n",
      " the tragic videoed killing of neda <PLH>##ha - soltan became iconic <PLH>what city's demonstrations?                                                                              \n",
      "Expected insertion classifier output \n",
      " the tragic videoed killing of neda agha - soltan became iconic following what city's demonstrations?                                                                              \n"
     ]
    }
   ],
   "source": [
    "class Model():\n",
    "    def __init__(self, vocab_size, hsz=768, lr=0.0001, max_placeholders=10, alpha=0, beta=0):\n",
    "        super().__init__()\n",
    "        self.transformer = TransformerEncoder(TransformerEncoderLayer(768, 8), 8)\n",
    "        self.p_classifier = PlaceholderClassifier(hsz, self.transformer, max_placeholders=max_placeholders).cuda()\n",
    "        self.t_classifier = TokenClassifier(hsz, self.transformer, vocab_size, 20).cuda()\n",
    "        self.d_classifier = DeletionClassifier(hsz, self.transformer).cuda()\n",
    "        self.dataset = QADataset(\"/virtualmachines/data/trivia_qa/qa/wikipedia-train.json\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoder = encoder\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.max_placeholders = max_placeholders             \n",
    "        \n",
    "        self.alpha = 0.5\n",
    "        self.beta = 0.5\n",
    "        self.p_loss = nn.CrossEntropyLoss()\n",
    "        self.t_loss = nn.CrossEntropyLoss()\n",
    "        self.d_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.optims = {\n",
    "            'p_classifier': optim.SGD(self.p_classifier.parameters(), lr=lr),\n",
    "            't_classifier': optim.SGD(self.t_classifier.parameters(), lr=lr),\n",
    "            'd_classifier': optim.SGD(self.d_classifier.parameters(), lr=lr),\n",
    "        }\n",
    "        \n",
    "        self.step = 0\n",
    "        self.loss = 0\n",
    "                        \n",
    "    def sample(self, bs=10, pad_to=30):\n",
    "        '''Sample an observation and return tensor tuples:\n",
    "        \n",
    "        2) (a) 1(a), but with PLH replacing each deleted token. For input to the token insertion classifier \n",
    "           (b) the number of placeholders tokens to insert at each index in 1(a) (for the placeholder classifier loss)\n",
    "        3) (a) the observation perturbed with insertion (tokens), for input to the token deletion classifier \n",
    "           (b) 2(a) (for the token insertion classifier loss)\n",
    "        '''\n",
    "        \n",
    "        v = random.random()\n",
    "        \n",
    "        # sample an untokenized string\n",
    "        y_ground = [self.dataset.sample() for i in range(bs)]\n",
    "        # tokenize/encode\n",
    "        encoded = [self.tokenizer.encode(s) for s in y_ground]\n",
    "        \n",
    "        insertion_input = InsertionInput(encoded)\n",
    "        deletion_input = DeletionInput(insertion_input, self.t_classifier)\n",
    "    \n",
    "        return insertion_input, deletion_input\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    def update_params(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.step()\n",
    "            \n",
    "    def encode_list(self, tokens):\n",
    "        if type(tokens) == list:\n",
    "            return encoder(torch.LongTensor([tokens]).cuda())[0]\n",
    "        return encoder(tokens)[0]\n",
    "            \n",
    "    def pretty_print(self, label, tokens):\n",
    "        if type(tokens) == torch.Tensor:\n",
    "            tokens = tokens.tolist()\n",
    "        pretty = \"%s \\n %s\" % (label, tokenizer.decode(tokens))\n",
    "        pretty = pretty.replace(\"[PAD]\",\"\")\n",
    "        print(pretty)\n",
    "        \n",
    "    def decode_step(self):\n",
    "        with torch.no_grad():\n",
    "            self.p_classifier.eval()\n",
    "            self.t_classifier.eval()\n",
    "            self.d_classifier.eval()\n",
    "\n",
    "            insertion_input, deletion_input = self.sample(bs=1)\n",
    "            self.pretty_print(\"Ground truth\", insertion_input.ground[0])\n",
    "            self.pretty_print(\"Ground truth post-deletion\", insertion_input.post_deletion[0].tolist())\n",
    "\n",
    "            step = 0\n",
    "            max_steps = 10\n",
    "            last = insertion_input.post_deletion\n",
    "            ground = last\n",
    "            \n",
    "            while True:            \n",
    "                if step > max_steps:\n",
    "                    ground = last\n",
    "                    break\n",
    "                \n",
    "                if step > 0 and (last.size() == ground.size() and torch.all(last == ground)):\n",
    "                    break\n",
    "                \n",
    "                print(\"Decode step %d\" % step)\n",
    "                \n",
    "                step += 1    \n",
    "                \n",
    "                # run a deletion pass\n",
    "                preds_deletes = self.d_classifier(self.encode_list(ground.cuda()).cuda())\n",
    "                if preds_deletes.size(1) > 0:\n",
    "                    deletions = torch.argmax(preds_deletes,2)\n",
    "                    assert ground.size(1) >= deletions.size(1)\n",
    "                    deleted = [ground[0,i].item() for i in range(deletions.size(1)) if deletions[0,i] == 0]\n",
    "                    ground = torch.LongTensor([deleted])\n",
    "                    self.pretty_print(\"Post-deletion\", deleted)\n",
    "                else:\n",
    "                    print(\"No deletions\")\n",
    "                    \n",
    "                preds_placeholders = self.p_classifier(self.encode_list(ground.cuda()).cuda())\n",
    "                # then run a placeholder pass                    \n",
    "                if preds_placeholders.size(1) == 0:\n",
    "                    print(\"No placeholders\")\n",
    "                    continue\n",
    "                    \n",
    "                placeholders = torch.argmax(preds_placeholders,2)\n",
    "                \n",
    "                reconstructed = []\n",
    "                added_placeholders = 0\n",
    "                for i in range(ground.size(1)):\n",
    "                    for j in range(min(self.max_placeholders, placeholders[0,i])):\n",
    "                        if len(reconstructed) < 512:\n",
    "                            reconstructed.append(plh)\n",
    "                            added_placeholders += 1\n",
    "                    if len(reconstructed) < 512:\n",
    "                        reconstructed.append(ground[0,i].item())\n",
    "\n",
    "                self.pretty_print(\"Post-placeholders\", reconstructed)\n",
    "                      \n",
    "                # then an insertion pass\n",
    "                preds_inserts = self.t_classifier(self.encode_list(reconstructed))\n",
    "                inserts = torch.argmax(preds_inserts, 2)\n",
    "                \n",
    "                output = []\n",
    "                for i in range(len(reconstructed)):\n",
    "                    if reconstructed[i] == plh:\n",
    "                        output.append(inserts[0,i].item())\n",
    "                    else:\n",
    "                        output.append(reconstructed[i])\n",
    "                self.pretty_print(\"Post-insert\", output)\n",
    "                last = torch.LongTensor([output])\n",
    "            if last is not None:\n",
    "                #print(last[0].tolist())\n",
    "                print(tokenizer.decode(last[0].tolist()))\n",
    "            else:\n",
    "                print(\"Couldn't decode\")\n",
    "            \n",
    "    def train_step(self):\n",
    "        loss = 0\n",
    "        self.zero_grad()\n",
    "        self.p_classifier.train()\n",
    "        self.t_classifier.train()\n",
    "        self.d_classifier.train()\n",
    "        \n",
    "        insertion_input, deletion_input = self.sample(bs=1)\n",
    "        \n",
    "        preds_deletes = self.d_classifier(encoder(deletion_input.post_insertion.cuda())[0].cuda())\n",
    "        preds_placeholders = self.p_classifier(encoder(insertion_input.post_deletion.cuda())[0])\n",
    "        preds_inserts = self.t_classifier(encoder(insertion_input.post_deletion_with_placeholders.cuda())[0])\n",
    "        loss = self.d_loss(torch.transpose(preds_deletes, 1, 2).cuda(), deletion_input.inserted_indices.cuda())\n",
    "        loss += self.p_loss(torch.transpose(preds_placeholders, 1, 2).cuda(), insertion_input.num_placeholders.cuda())\n",
    "        loss += self.t_loss(torch.transpose(preds_inserts,1,2).cuda(), torch.LongTensor(deletion_input.ground_padded).cuda())\n",
    "        self.step += 1\n",
    "        self.loss += loss\n",
    "        if self.step % 25 == 0:\n",
    "            print(self.step)\n",
    "            self.pretty_print(\"Ground\", insertion_input.ground[0])\n",
    "            self.pretty_print(\"Input to deletion classifier\", deletion_input.post_insertion[0])\n",
    "            self.pretty_print(\"Expected deletion classifier output\", apply_deletion(deletion_input.post_insertion[0], deletion_input.inserted_indices[0]))\n",
    "            self.pretty_print(\"Input to placeholder classifier\", insertion_input.post_deletion[0])\n",
    "            self.pretty_print(\"Expected placeholder classifier output\", apply_placeholders(insertion_input.post_deletion[0], insertion_input.num_placeholders[0]))\n",
    "            self.pretty_print(\"Input to insertion classifier\", insertion_input.post_deletion_with_placeholders[0])\n",
    "            self.pretty_print(\"Expected insertion classifier output\", deletion_input.ground_padded[0])\n",
    "        if self.step % 50 == 0:\n",
    "            print(self.step)\n",
    "            print(self.loss / 50)\n",
    "            self.loss = 0\n",
    "            self.decode_step()\n",
    "        \n",
    "        loss.backward()\n",
    "        self.update_params()\n",
    "\n",
    "model = Model(len(tokenizer))\n",
    "for i in range(10000):\n",
    "    model.train_step()\n",
    "model.decode_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\"hello how are you\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
